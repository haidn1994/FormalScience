# 통계학(Statistic: 즉, 통계량에 관한 학문)

참고문헌을 통해 정리하고 공부합니다.

## 1. 통계학의 기본개념

### 통계학?

통계학은 자료를 의사결정에 도움이 되는 의미있는 정보로 전환하는 방법에 관하여 연구하는 학문이다.

### 자료와 정보(Data and Information)

자료는 사람, 물건, 조건, 상황 등을 묘사한 기본적인 사실의 집합을 말하며, 일반적으로 가공되기 전의 상태를 말한다.  
반면에 정보는 의사결정에 도움이 되도록 요약되거나 도표로 표시된것으로써 효과적인 의사결정을 위해 가공된 형태의 자료를 말한다.


자료와 정보의 정확한 구분은 사용자, 즉 의사결정자의 보는 시각과 이를 활용하는 상황에 의하여 결정된다.

### 통계의 종류

통계를 크게 구분하여 보면, 기술통계(descriptive statistics)와 추론통계(inferential statistics)로 구성된다.
수집된 자료를 이용하여 표본의 통계량을 구하거나 자료를 요약하여 정보로 만드는 데 사용되는 통계를 기술통계라 하며,   
표본의 통계량을 이용하여 모집단의 특성을 나타내는 모수를 추청하거나 모수에 대한 가설을 검정하는 데에 사용되는 통계를 추론 통계라 한다.  


여기서 모집단의 특성을 나타내는 값들, 예를 들어 K대학교 학생 전체의 평균키, 평균 몸무게, 평균IQ지수, 평균수능성적 등을 모수(Parameter)라 하고,  
표본으로 선정된 100명의 평균키, 평균몸무게, 평균IQ지수 등과 같이 모수에 대응하는 값으로서 표본의 특성을 나타내는 값들을 통계량(Statistic)이라 한다.  
또한 특정한 표본의 통계량 값으로 측정된 구체적인 값을 통계치라고 한다.  

### 기술통계(descriptive statistic)

기술통계(descriptive statsics)는 자료의 특성을 적절하게 그림이나 도표 또는 수치로 요약하여 기술함으로써   
자료를 의사결정을 위한 정보로 바꾸는 과정에서 활용되는 통계를 말한다.  

### 추론통계(inferential statistic)

추론통계(inferential statistics)는 모집단에서 추출한 표본의 특성을 나타내는 통계량으로  
모집단의 특성을 나타내는 모수를 추정하거나 모수에 대한 가설을 통계량으로 검정하는 데에 사용되는 통계를 말한다.

## 2. 통계분석을 위한 자료

통계는 자료로부터 시작한다. 효과적인 의사결정에 필요한 정보를 추출하기 위해서는 자료가 필요하고,  
이러한 자료는 관심대상을 선정한 후, 그 대상의 특정한 속성을 척도(scale)를 이용해서 측정(measure)한 다음  
이를 변수(variable)값으로 축적함으로써 만들어진다.  

* 자료 수집 과정
>  분석 문제의 결정 >> 대상의 선정 >> 관심 속성의 결정 >> 척도의 선정 >> 측정 >> 결과값을 변수에 축적

관심대상의 속성을 관찰하여 변수값으로 저장하는 과정을 측정(measure)이라 하고,  
그 결과로 생성된 변수값들을 총칭하여 자료(data)라 한다.  


그리고 이들(측정도구들과 측정 규칙)을 이용하여 측정된 값들의 특성에 따라 측정도구나 측정규칙을 구분할 수 있는데,  
이를 척도(scale)라 한다.  

### 자료

자료(data)는 사람, 물건, 조건, 상황등을 묘사하는 기본적인 사실의 집합으로 일반적으로 정보로 가공되기 전의 상태를 말한다.  
대부분의 자료는 처음에는 **질적자료**에 속하나, 척도를 이용하여 수치로 전환함으로써 **양적자료**가 된다.  
수치로 표시된 양적자료에는 **변수(variable)**와 **상수(constant)**가 있다.  
변수는 2개 이상의 서로 다른 값을 갖는 양적자료이고, 상수는 오직 한 가지의 수치값만을 갖는 양적 자료이다.  


또한 변수는 이산변수(discrete variable)와 연속변수(continous variable)로 나눌 수 있다.  
일반적으로 컴퓨터나 자동차 판매대수처럼 정수값을 갖는 것을 이산변수라고 하고,  
몸무게나 온도 등과 같이 소수점 이하 연속적으로 이어지는 값을 갖는 것을 연속변수라고 하면된다.  

### 측정

측정은 관찰대상이 가지고 있는 속성의 값을 일정한 규칙으로 만들어진 도구(척도)를 이용하여 계량화하는 것,  
즉 관찰대상의 속성에 대하여 기술적으로 수치를 부여하는 행위를 말한다.  

### 척도

자료는 수치화 여부에 따라 질적자료와 양적자료로 구분된다.  ...(중략)...  
척도(scale)는 관찰대상의 속성을 측정(measure)하여 그 값을 숫자로 나타내는 일종의 규칙을 말한다.  
즉, 질적인 자료를 양적인 자료로 전환시켜 주는 도구라 할 수 있다.  
이러한 척도에는 이를 이용하여 측정한 결과로 나타나는 수치의 특성에 따라  
명목척도(nominal scale), 서열척도(ordinal scale), 등간척도(interval scale), 
비율척도(ratio scale)의 6가지 종류가 있다.  


척도를 이용하여 생성된 양적자료에는 변수(variable)와 상수(constant)가 있다.  
질적변수의 측정에 사용되는 척도를 질적척도라고 하고, 양적변수의 측정에 사용되는 척도를 양적 척도라 한다.  

#### 명목척도

명목척도(nominal scale)는 관찰대상이 갖는 속성에 따라 관찰대상을 상호 배타적인 범주로 구분하는 것으로서,  
관찰대상을 단순히 범주로 분류하기 위한 목적으로 숫자를 사용하는 척도를 말한다.  
따라서 숫자로서 양적의미는 없으며, 연산도 의미가 없다.  

#### 서열척도

서열척도(ordinal scale)는 관찰대상이 가지고 있는 속성의 크기를 측정하여 크기 순서대로 대상의 순위를 나타내는 것으로써,  
명목척도와 마찬가지로 대상을 서로 구분할 수 있을 뿐만 아니라, 속성의 크기에 따라 대상의 순서를 정할 수 있다.  
하지만 순서이외의 양적의미는 없으며, 연산 또한 의미가 없다.  


다시 말해, 서열척도는 서열 간의 차이, 즉 간격에 대해서는 측정하지 않고,  
오직 대상들의 순서에 관한 정보만을 측정하는 데에 사용되는 척도이다.  


또한 서열척도는 명목척도가 가지는 정보를 모두 가진다.  
#### 등간척도

등간척도는(interval scale)는 속성 크기에 따른 관찰 대상의 서열뿐 아니라 
대상들 간에 어느 정도 차이가 있는가에 대한 정보도 포함하고 있다.  
즉, 관찰 대상들이 가지고 있는 속성의 상대적 크기를 측정하여 대상 간에 서로 비교할 수 있도록 하는 척도를 말한다.  


등간척도는 앞에서 설명한 명목척도와 서열척도가 제공할 수 있는 정보를 모두 포함하여 
관찰대상이 가지고 있는 속성들의 상대적 크기를 나타내는 정보를 측정할 수 있다.  
그러나 속성의 **절대적 크기**는 측정할 수 없으므로*(수직선과 같이 명확한 기준이 없다.)*
사칙연산 중에서 가감(+, -)의 계산은 가능해도 비율처럼 곱하거나 나누는 승제(\*, (%,/))의 계산은 불가능하다.  

#### 비율척도

마지막으로 절대적인 기준이 존재하는 척도로 비율척도(ratio scale)가 있다.  
비율척도는 절대적인 기준을 가지고 속성의 상대적 크기 비교는 물론 절대적 크기까지 측정할 수 있도록   
비율의 개념이 추가된 척도를 말한다.  


비율척도로 측정된 값들은 서로 곱하거나 나누는 것이 가능하다.  
따라서 비율 척도로 측정된 값들이 가장 많은 정보를 포함하고 있다고 볼 수 있다.  


#### 척도의 특징

척도는 비율척도, 등간척도, 서열척도, 명목척도의 순서대로 많은 정보를 포함하고 있다. ...(중략)...  
조사자가 필요로 하는 정확한 정보를 얻기 위해서는 응답자에게 너무 큰 부담을 주지 않는 적당한 수준에서  
정보를 추출할 수 있어야 한다. 응답자에게 너무 큰 부담을 준다면 대답하지 않거나 거짓으로 대답하는 등,  
각종 부작용에 시달리게 된다.  

### 변수

변수(variable)란 척도를 이용하여 관심대상이 되는 개체(item)의 속성을 측정한 값을 대표하여 일컫는 말이다.  
(여기에 더해, 상수와 달리 2개 이상의 값을 가질 수 있는 경우에도 변수라고 한다.)  
변수는 연구자가 관심을 가지고 있는 대상의 속성을 척도로 측정하여 수치로 계량화하는 규칙이라고 정의할 수 있다.  
변수를 이와 같이 규정하면, 하나의 속성값을 측정하더라도 그 표현 규칙을 다양하게 정의함에 따라 여러 개의 변수들을 생성할 수도 있다.  


변수는 관심 대상의 속성을 측정하여 그 값을 수치로 나타내는 하나의 규칙으로 보는 것이 보다 이해하기 쉽고 정확한 표현임을 알 수 있다.  
일반적으로 변수는 연산이 가능한가에 따라 연산이 의미가 없는 질적변수(qualitative variable)와   
연산이 의미가 있는 양적변수(quantitative variable)로 구분할 수 있다.  
질적변수는 속성의 값을 나타내는 수치의 크기가 의미가 없는 변수로서 비계량적변수 혹은 논메트릭(non-metric)변수라고도 말한다.  


반면에 계량적 변수 혹은 메트릭(metric)변수라고도 불리는 양적변수는 측정한 속성값을 연산이 가능한 의미있는 수치로 나타낼 수 있다.  
또한 이러한 양적변수는 학생수나 자동차 판매대수와 같이 정수값만을 취할 수 있는 이산변수(discrete variable)와   
몸무게나 키와 같이 연속적인 실수값을 취할 수 있는 연속변수(continous variable)로 나누어 진다.  


또한, 사용되는 용도에 따라 변수를 독립변수(independent variable)와 종속변수(dependent variable)로 구분하기도 한다.  
변수를 사용하는 상황에 따라 독립변수를 원인, 설명, 예측변수로, 그리고 종속변수를 결과, 목적, 타깃 변수로 부르기도 한다.  



## 3. 자료수집의 대상

## 4. 분포의 특성

## 5. 확률과 확률이론

확률(probability)은 통계학이나 조사방법론에서 매우 중요한 개념이다.  
확률개념이 중요한 이유는 대부분의 통계분석은 전체 자료를 분석하는 것이 아니라 모집단으로부터 추출한 표본의 자료를 분석하기 때문이다.  
(그래서 통계학의 영어 명칭이 **Statistic**이다!)  


모집단으로부터 추출된 표본(Sample)의 특성을 나타내는 통계량은 확정적인 값이 아니라   
선정된 표본에 따라 값이 달라지는, 즉 확률의 개념을 포함하는 값이 될 수 밖에 없다.  
요약하면, 통계분석에서 사용되는 표본은 모집단으로부터 추출할 수 있는 여러 가능한 표본 중의 하나에 불과하다.  
따라서 표본을 선정하는 행위는 확률 개념을 자동적으로 포함하기 때문에   
확률을 충분히 이해해야 추정 및 가설검정과 같은 통계분석을 정확하게 이해할 수 있다.  

### 확률의 정의

확률이란 경험 혹은 실험의 결과로 특정한 사건(event)이나 결과가 발생할 가능성을 말한다.  
확률은 우리의 일상생활에서 항상 사용되며, 대부분의 의사결정은 확률 혹은 확률에 대한 판단을 필요로 하고 있다.  


#### 주관적 확률

확률은 크게 주관적 확률과 객관적 확률로 구분해 볼 수 있다.   
주관적 확률은 의사 결정자의 지식, 정보 및 경험을 바탕으로 한 주관적 판단에 의하여 결정되는 확률을 말한다.  
그러나 이러한 주관적 확률된 평가자의 지식이나 정보, 그리고 경험이 충분하게 축적됨에 따라 객관성을 띄게 될 가능성이 점차 높아진다.  

#### 객관적 확률

객관적 확률이란 특정 사건이 발생할 가능성을 객관적으로 명확하여 누구나 쉽게 알 수 있는 경우나,  
동일한 실험을 무수히 반복적으로 수행할 경우 특정한 사건이 발생할 수 있는 확률을 말한다.  
일반적으로 객관적인 확률에는 고전적 확률개념(classical probability)과  
장기적 상대도수 확률개념(long-run relative frequency probability)의 두 종류가 있다.  

##### 고전적 확률

고전적 확률은 실제적인 경험에 의한 것이 아니고, 특정한 결과가 발생할 가능성을 직관적이며  
객관적으로 판단하여 추정한 확률이다. 이와 같이 고전적 확률은 실제 실험에 앞서 논리적 유추에 의한 확률개념이라는 점에서   
사전적 확률(prior prpbability)이라고도 한다.  
우리가 수학시간에 배우던 확률이 가장 고전적 확률에 가깝다.  

##### 장기적 상대도수 확률

장기적 상대도수 확률은 실제 경험이나 경험에 근거한 확률개념이다.  
즉, 특정 사건이 발생할 수 있는 상대적 가능성을 판단하기 위하여 실제로 수많은 실험을 수행하고   
그 결과들을 직접 관찰하고 기록한 결과로 판단하는 확률을 말한다.  
이러한 이유로 장기적 상대도수 확률을 사후적 확률(posterior probability)이라 부르기도 한다.  


끊임없이 시행횟수를 늘려 반복적으로 실험을 시행하는 경우, 어느 특정한 값에 수렴하는 확률값을 얻을 수 있는데,   
이것이 바로 장기적인 상대도수개념에 의한 확률이 된다. 그러나 니와 같은 장기적 상대도수에 의한 확률은  
실제 수많은 실험과 관찰을 통해서만 구할 수 있다는 어려움이 있다.  
따라서 현실적으로는 상대도수의 극한치를 추정하여 구하거나 한 사건이 발생할 기대 상대도수를 구하여 확률을 산출하기도 한다.  

### 실험과 표본공간

실험(experiment)이란 어떤 행위의 결과를 관찰하고 측정하여 그 결과에 대해 구체적인 값을 부여하는 것을 말한다.  
따라서 실험이라는 것은 어떤 일을 수행하고 그 결과로 나온 값을 기록하여 자료로 남기는 행위를 말한다.  


실험결과를 효과적으로 표현하고 설명하기 위해서는   
표본점(sample point)과 표본공간(sample space)이라는 개념에 대하여 살펴볼 필요가 있다.  
표본점은 한 번의 실험 결과로 얻을 수 있는 결과를 말한다.  
표본점은 단일사상 혹은 단일사건(simple event)이라고도 불린다.  


> 표본공간이란 실험을 통해서 얻을 수 있는 모든 가능한 표본점들의 집합을 말한다.  


### 확률과 표본공간

조사를 위하여 모집단으로부터 표본을 추출하는 것도 일종의 실험(experiment) 행위로 볼 수 있다.
따라서 모집단으로부터 추출된 표본은 하나의 표본점으로서 표본으로 얻을 수 있는 수없이 많은 표본점 중의 하나로 볼 수 있다.  


실험 결과 특정한 표본점을 얻을 수 있는 확률은 모든 가능한 표본점의 수, 즉 표본공간상의 표본점의 수 분의 1이다.  
이와 같이 하여 모집단으로부터 일정한 수의 표본을 추출하는 경우에는 자연스럽게 확률이라는 개념이 포함되게 된다.  
정리하면 다음과 같다.

* 모집단에서 표본을 추출하는 과정은 일종의 실험이라 할 수 있다.  
* 모집단으로부터 추출 가능한 모든 표본들의 집합(모든 표본점들의 집합)으로 표본공간이 형성된다.  
* 표본추출과정을 통하여 추출된 하나의 특정한 표본은 표본공간상에 있는 하나의 표본점에 불과하다.
* 특정한 표본이 추출될 수 있는 확률은 1/(표본공간 상의 표본점 수)이 된다.
* 따라서 표본을 추출하여 표본으로부터 얻게 되는 모든 정보에는 자연스럽게 확률의 개념이 포함된다.  

### 확률의 종류

일반적으로 확률에는 한계확률(marginal probability)과 결합확률(joint probability) 그리고 조건부 확률(conditional probability)이 있다. ...(중략)...


2개의 변수가 교차되어 만들어진 빈도교차표상에서 하나의 관측치가 행이나 열 어느 한 변수에 의해서만 
구분되는 특정 집단에 속할 확률을 한계확률(marginal probability)이라 한다.  


집단을 구분하는 행과 열의 2개 변수를 동시에 고려해서 구한 확률을 한계확률과 구분하여  
결합확률(joint probability)이라한다.  


특정한 조건하에서 구하게 되는 확률을 조건부 확률(conditaional probability)이라 한다.  
이러한 조건부 확률이 한계확률이나 결합 확률과 다른 점은 사건을 선정하는 조건을 붙임으로써 사건이 발생할 수 있는  
표본공간 자체가 제한되어 바뀐다는 점이다.  


#### 한계확률(marginal probability)

아무런 조건이 없는 상태에서 A라는 사건이 발생할 확률을 비조건확률 또는 한계확률이라고 하고 P(A)로 표시한다.  
빈도교차표 상의 행과 열의 빈도합을 행과 열의 합(marginal total)이라하고, 이러한 행과 열의 합을 빈도 전체의 합으로 나누면  한계 확률을 구할 수 있다.  


#### 결합확률(joint probability)
결합확률(joint probability)이란 두 개 이상의 사건이 동시에 발생할 가능성을 나타내는 확률을 말한다.  
사건 A와 사건 B가 동시에 발생할 결합확률을 기호로는 P(A inter B)로 표시한다.(또는 P(A cup B))
다음과 같은 예를 들어볼 수 있다.  ...(중략)...  


임의로 선정된 학생이 특정한 과일을 선호하는 사건과 이 학생의 성별을 구분하는 사건이 서로 독립적인 경우에 결합확률은  
성별을 구분하는 한계 확률과 선호하는 과일을 구분하는 한계확률을 서로 곱하여 구할 수도 있다.  


한계확률을 서로 곱하여 결합확률을 구하는 방법은 사전에 두 사건이 서로 독립적인지를 단정할 수 없기 때문에  
결합확률을 구하는 일반적인 방법으로 사용하기는 어렵다. 그러나 역으로 한계확률을 서로 곱하여 구한 확률과  
실제 빈도교차표를 이용하여 구한 결합확률을 비교함으로써 빈도교차표상의 두 사건이 서로 독립적인지 아닌지를   
판단하는 기준으로 사용할 수는 있다.  

#### 조건부 확률(conditional probability)
조건부 확률은 이미 하나의 사건이 발생한 상태에서 또 다른 사건이 발생할 가능성을 나타내는 확률이다. ...(중략)...  
이처럼 조건부 확률은 전체가 아니라 전체 중에 특정한 조건을 만족시키는 일부를 새로운 표본공간으로 하여 확률값이 산출된다.  
따라서 대부분의 경우 표본공간이 작아짐으로써 조건부 확률(P(B|A))은 일반적인 결합확률P(A inter B)보다 큰 확률 값을 같게 된다.  
(즉, 조건부 확률을 직관적으로 이해해보자면 **표본공간의 변경**이라고 할 수 있다.)

### 확률의 연산 법칙

확률의 연산법칙에는 **덧셈법칙**과 **곱셈법칙**이 있다.  
앞에서 설명한 결합확률, 한계확률, 조건부 확률 간의 관계를 확률의 연산법칙을 이용하여 설명하면 다음과 같다.  
먼저 임의의 두 가지 사건 A와 B가 서로 배반적(exclusive)이냐 배반적이지 않느냐에 따라 달라지는 확률의 덧셈법칙과,  
임의의 두 사건 A와 B가 서로 독립적이냐 독립적이지 않느냐에 따라 달라지는 확률의 곱셈법칙에 대해 설명한다.  
그리고 곱셈법칙을 통하여 조건부 확률과 결합확률의 관계를 설명하도록 한다.  

#### 덧셈법칙

먼저 알고 넘어가야 할 사항이 있다.  
> n(A union B) = n(A) + n(B) - n(A inter B)
이것을 집합을 덧셈법칙이라 한다 이는 확률에서도 똑같이 통용된다.


> P(A union B) = P(A) + P(B) - P(A inter B)
이를 집합의 덧셈 법칙에 대응하는 확률의 덧셈법칙이라고 한다.


이러한 확률의 덧셈법칙은 두 사건이 상호 배반적인 경우와 그렇지 않은 경우로 구분해 볼 수 있다.  
두 사건이 상호 배반적이라는 말의 의미는 사건 A와 사건 B가 동시에 일어나는 경우가 없다는 것을 의미한다.  
위와 같은 상황과 반대, 즉 사건 A와 사건 B가 동시에 일어나는 경우가 있다면 상호 배반적이지 않다고 한다.  
그리고 상호 배반적이냐 그렇지 않느냐에 따라서 덧셈법칙의 모양이 조금 달라진다.  

1. 상호 배반적(mutually exclusive events): P(A union B) = P(A) + P(B)
2. 상호 배반적이지 않음: P(A union B) = P(A) + P(B) - P(A inter B)


#### 곱셈법칙

확률의 곱셈법칙은 조건부 확률을 이용하여 설명할 수 있다. 하나의 사건이 발생한 상태에서  
또 다른 사건이 발생할 가능성을 나타내는 확률을 조건부 확률이라고 한다.  
그 식은 다음과 같다.  

> P(B|A) = P(A inter B) / P(A)

이러한 식을 이용하여 조건부 확률을 구하기 위해서는 두 가지의 전제 조건이 필요하다.  


**첫째**, 식에서 분모에 있는 사건 A가 발생할 확률 P(A)가 적어도 0이 아니어야 한다.  
즉, (P(A) != 0)  


**둘째**, 사건 A와 사건 B가 상호 배반적인 사건(mutually exclusive events)이 아니어야 한다.  
즉, 사건 A와 사건 B의 결합확률 P(A inter B)이 0이 아니어야 한다.  
(P(A inter B) != 0)


조건부 확률을 구하는 식에서 분모를 이항하면 P(A inter B) = P(A) X P(B|A)와 같은 식을 구할 수 있다.  
즉, 사건 A와 사건 B가 동시에 발생할 결합확률 P(A inter B)는 사건 A가 발생할 확률 P(A)에 사건 A가 발생한 상태에서  
사건 B가 발생할 조건부 확률 P(B|A)를 곱하여 구할 수 있다.  


또한 사건 A와 사건 B를 바꾸어 생각하면, 결합확률 P(A inter B)는 사건 B가 발생할 확률 P(B)에 사건 B가 발생한 상태에서  
사건 A가 발생할 조건부 확률 P(A|B)를 곱하여 구할 수 있다.  
따라서 다음 식이 성립하여 이것을 확률의 곱셈 법칙이라 한다.  

> P(A inter B) = P(A) X P(B|A) = P(B) X P(A|B)

**"독립적이냐? 독립적이지 않느냐"**도 곱셈법칙의 꼴이 달라지므로 유의하여 보도록 한다.  
사건 A와 사건 B중에 어느 한 사건의 발생이 다른 한 사건의 발생에 전혀 영향을 미치지 못하는 경우,  
두 사건은 서로 독립적이라고 한다.  

### 순열과 조합

조합은 서로 다른 n개의 개체에서 k개를 택하는 경우의 수를 말한다.  
순열은 조합에서 한 단계 더 나아가 선택된 k개를 나열하는 방법, 즉 순서까지 고려한 경우의 수를 의미한다.  

#### 순열 

서로 다른 n개의 개체에서 k개를 선택한 다음, 순서를 고려하여 배열하는 경우의 수를 순열(Permutation)이라 하며,  
n개에서 k개를 선택하여 배열하는 수열을 기호로는 P(n, k)로 표시하고 n permutation k라 읽는다.

#### 조합

### 베이지안 이론

베이지안 이론은 베이즈 정리(Bayes theorem)를 바탕으로 이루어지며, 주어진 사전확률 정보를 이용하여  
사후 확률을 예측하는 이론이다. 사건이 발생하고 난 후, 사건 발생의 원인에 대한 확률(사후 확률)을 사건발생 전에  
이미 알고 있는 정보(사전 확률)를 이용하여 구하는 것이다.  


확률변수란 확률과 연동하여 특정한 값을 갖는 변수라고 할 수 있다.  
확률분포(probability distribution)는 이러한 확률변수가 가질 수 있는 값에 따른 확률을 
도수 분포표나 그래프로 나타낸 것이다. 즉, 확률 변수의 분포를 말한다.  


## 6. 확률변수와 확률분포
확률이란 경험이나 실험결과로 특정한 사건이 일어날 수 있는 가능성을 말하는 것이고,  
변수란 관심대상의 속성을 척도를 이용하여 측정한 값들을 대표하는 말이다.  


따라서 확률변수는 확률의 개념과 변수의 개념이 결합된 것에 해당한다.  
모집단으로부터 추출한 표본의 평균이나 분산과 같은 통계량은   
확률과 변수의 개념을 모두 포함하고 있는 대표적인 확률변수에 해당한다.   
또한 표본으로부터 구한 표본통계량은 확률 개념이 포함된 대표적인 확률변수이다.  

### 확률 변수의 정의

변수는 일종의 규칙이다. 따라서 확률변수도 표본공간상에 나타는 모든 표본점들에 수치를 부여하는 규칙으로 정의할 수 있다.  
표본공간상의 표본점들을 일정한 규칙을 사용하여 수치값으로 전환하는 방법은 수없이 많다.  
따라서 하나의 표본공간으로부터 수없이 많은 확률변수들이 생성될 수 있다.  

### 확률 변수의 종류

변수가 이산변수와 연속변수로 나누어지는 것과 같이 확률변수도 이산확률변수와 연속확률변수로 나누어진다.  
이산확률변수는 이산변수처럼 확률변수가 가질 수 있는 값들이 정수와 같아 그 값을 정확하게 알 수 있는 변수를 말한다.  
반면, 연속확률변수는 연속변수처럼 확률변수가 가질 수 있는 값들의 개수를 일일이 셀 수 없는 변수를 말한다.  

### 확률 분포의 정의
확률 분포(probability distribution)는 확률변수가 특정한 값을 가질 확률, 즉 상대적 가능성을 나타낸 것으로  
모든 가능한 확률변수값과 그 값이 발생할 가능성인 확률값을 도수분포표나 그래프로 나타낸 것이다.  
즉, 확률 변수가 가질 수 있는 값과 그 값을 가질 확률을 요약해서 알기 쉽게 표시한 것을 확률 분포라고 한다.  
일반적으로 그래프로 나타낸 것만을 확률분포로 생각하는 경향이 있으나, 도표도 확률분포로 간주하여야 한다.  
또한, 그래프로 확률분포를 나타내는 경우에 확률분포를 나타내는 함수를 확률함수(Probability function)라고 한다.  


### 확률 분포의 종류

확률분포는 확률변수의 종류에 따라 이산확률분포와 연속확률분포로 나누어진다.  
이산확률분포는 이산확률변수의 확률분포이고, 연속확률분포는 연속확률 변수의 확률분포이다.  


하나의 표본공간을 이용하여 생성할 수 있는 확률변수의 수가 무수히 많듯이, 확률변수를 나타내는 확률분포 또한 무수히 많고 다양하다.  
따라서 대부분의 경우 확률 분포가 어떠한 형태와 규칙을 가지고 있는지를 정확하게 파악하기 어렵다.  
연속확률분포보다 단순한 이산확률분포의 경우에도 무수히 많은 모양의 분포가 있을 수 있다.  
따라서 다양한 모양의 확률분포에서 일반화된 어떤 규칙을 찾아 분포를 수식으로 표현하는 데에는 적지않은 어려움이 있다.  
즉, **대부분의 확률분포는 수식으로 표현하기 어렵다.**  


하지만 수식으로 표현이 가능한 확률분포가 **없는 것은 아니다**.  
무수히 많은 다양한 확률분포 중에서 어느 정도 그 특성을 파악할 수 있는 대표적인 확률분포들이다.  
대표적인 이산확률분포로는 이항분포, 초기하분포, 그리고 포아송분포가 있다. 이들 분포에 대해서는 7장에서 자세하게 설명한다.  
또한 대표적인 연속확률분포로는 정규분포, t분포, 카이제곱분포와 F분포가 있다.(지수분포 등등...)  
이러한 연속확률분포에 대해서는 제 8장에서 자세히 알아보도록 한다.  

### 확률함수

확률분포를 함수로 나타낸 것을 확률함수(probability function)라고 한다.  
확률함수에는 이산확률변수의 분포를 나타내는 확률질량 함수(P.M.F: Probability Mass Function)와  
연속확률변수의 분포를 나타내는 확률밀도함수(P.D.F: Probability Density Function)가 있다.  


연속확률변수는 이산확률변수와 달리 명확하게 구분되는 특정 값이 아니라 수없이 많은 실수값을 가질 수 있다.  
따라서 연속확률변수가 특정한 실수값들을 가질 수 있는 확률은 0이다.  
그러나 연속홧률변수가 이산확률변수와 같이 특정한 값을 가질 수 있다는 가정하에 그 값을 가질 수 있는 확률을 가상적으로 표현한 것.  
즉, X축에서 연속확률밀도 함수에 이르는 가상적인 확률을 나타내는 값을 확률밀도라고 한다.  
또한 이러한 확률밀도값을 연결하여 곡선으로 나타낸 것을 확률분포곡선,  
그리고 이를 함수식으로 나타낸 것을 확률밀도함수(p.d.f)라 한다.  

## 7. 이산확률분포

### 이항분포

이산확률분포로는 이항분포, 초기하분포, 그리고 포아송분포 등이 있으며  
연속확률분포로는 정규분포, t분포, 카이자승분포, F분포, 지수분포 등이 있다.  
처음에는 이산확률 분포의 한 종류는 이항분포에 대해서 알아보자.  

#### 베르누이 시행

베르누이 시행이란 상호 배반적인 2가지 결과만을 기대할 수 있는 시행을 말한다.  
예를 들어, 동전을 던졌을 때 나올 수 있는 앞면과 뒷면, 각종 시험의 합격이나 불합격, 각종 시합의 승자와 패자  
선거의 낙선과 당선등 서로 상호배반적인 2가지 결과만을 기대할 수 있는 경우가 베르누이 시행에 해당한다.  


베르누이 시행에서는 결과로 나타나는 2가지 중에 하나를 성공(Success)이라 하고, 또 다른 한 가지 결과를 실패(failure)라 한다.  
그러나 여기서 성공과 실패는 둘을 구별하기 위한 말일 뿐이지, 좋고 나쁨을 의미하지는 않는다.  
또한 이렇게 베르누이 시행 결과로 얻을 수 있는 값을 나타내는 확률변수를 베르누이 확률변수라 한다.  
이러한 베르누이 시행의 특징을 정리하면 다음과 같다.  

1. 베르누이 시행의 결과를 나타내는 확률변수는 1(성공) 혹은 0(실패)값만을 갖는다.  
2. 베르누이 시행에서 성공확률과 실패확률의 합은 항상 1이 된다.(확률의 정의를 생각해보라!)
3. 각각의 베르누이 시행은 서로 **독립적**이기 때문에 여러 번에 걸친 베르누이 시행 간에는 서로 영향을 미치지 않는다.  

#### 이항분포의 개관

한 번 이상 반복 실시한 베르누이 시행 결과의 합을 변수값으로 하는 확률변수의 분포를 이항확률분포 혹은  
간단히 이항분포(binomial distribution)이라 한다.  
이항분포의 모양을 결정하는 값들은 단일 시행, 즉 베르누이 시행에서의 성공할 확률(PI)과 시행횟수(n)이다.  
일반적으로 성공할 확률이 0.5에 가까울수록 그리고 시행회수가 많을수록 이항확분포는 종 모양의 정규분포에 가까워진다.  
그러나 반대로 성공할 확률이 0.5와는 달리 매우 크거나 작을 경우, 
그리고 시행회수가 적을수록 이항분포는 한쪽 극단으로 치우친 분포를 한다.  


이항 분포의 특징은 다음과 같다.  

1. 이항확률변수의 값은 여러 개의 베르누이 시행 결과의 합이 된다.  
2. 이항확률변수값을 구성하고 있는 각각의 베르누이 시행은 상호 독립적이다.  
3. 이항확률변수값을 구성하고 있는 각각의 베르누이 시행에서 성공할 확률은 모두 동일하다.  

#### 이항분포의 정의와 특징

다시 한번 복습해 보자.  

* 이항 분포의 정의
	* 여러 개의 베르누이 시행 결과의 합을 변수값으로 갖는 확률변수를 이항확률변수라 하고 이 변수의 분포를 이항분포라 한다.  
	* 이항분포의 모양은 개별적인 베르누이 시행에서의 성공할 확률(PI)과 시행회수(n)에 따라 결정된다.  

* 이항분포의 특징
	* 이항확률변수의 값은 여러개의 베르누이 시행 결과의 합이 된다.
	* 이항확률변수를 구성하고 있는 각각의 베르누이 시행은 상호 독립적이다.  
	* 이항확률변수를 구성하고 있는 각각의 베르누이 시행에서 성공할 확률은 모두 동일하다.  

#### 이항분포의 확률질량함수

#### 이항분포의 개값과 분산

### 초기하분포

> 참고: 초기하분포는 이항분포로부터 유도된다.

이항분포에서 베르누이 시행은 거로 독립적이어서 시행에서 성공할 확률은 항상 동일하다.  
그러나 각 시행이 서로 독립적이지 않고, 유한 모집단을 대상으로 비복원 추출로 표본을 선정하는 경우.  
즉 표본을 추출할 때마다 표본을 추출하는 표본공간이 매번 변하는 경우의 확률변수는 어떠한 분포를 하는가?  
이러한 확률변수에 적용할 수 있는 분포가 초기하분포이다.  


다시말해, *표본을 추출하는 시행결과가 서로 독립적인 복원추출발법을 사용하는 경우에 확률변수는 이항분포*하고,  
반면에 *표본을 추출하는 시행 결과가 서로 영향을 미치는 유한 모집단을 대상으로 비복원추출방법을 사용하는 경우에 확률변수는 초기하분포한다.*  


이항분포와 초기하분포는 앞에서 설명한 바와 같이 표본추출방법이 복원추출이냐 아니면 비복원 추출이냐에 따라 구분된다.  
복원추출방법을 사용하게 되는 경우 공을 뽑는 사건이 사로 독립적인 베르누이 시행이 된다.  
비복원추출방법을 사용할 경우에는 공을 뽑는 사건이 서로 영향을 미치는 초기하분포로 판단할 수 있게 된다.  

### 포아송분포
일상생활에서는 **일정한 시간이나 거리 혹은 면적 등**에서 발생하는 특정한 사건의 수에 관심을 보이는 경우가 있다.  
예를 들면, 새로 구입한 자동차에서 발견되는 흠집의 수, 하루 동안 고장나는 기계의 대수,  
일정시간 내에 은행창구를 방문하는 고객의 수, 1년간 아파트 엘리베이터가 고장난 횟수, 1주일 간에 발생하는 정전회수 등  


뭔가 규칙이 보이는가? 포아송분포는 시간과 큰 연관성이 있다. 
이러한 경우 발생하는 특정한 사건의 횟수를 확률변수값으로 하는 분포가 바로 포아송분포(poisson distribution)이다.  
이항분포와 포아송분포는 모두 사건의 발생횟수를 나나태는 이산확률변수의 분포라는 점에서 유사하지만,  
확률변수의 크기 면에서는 차이가 있다. 일반적으로 이항확률변수의 최대값은 변수를 구성하고 있는 베르누이 시행의 수로 제한된다.  
즉, 조사된 표본의 크기, 즉 베르누이 시행의 개수가 이항확률변수의 최대값이 된다.  


그러나 포아송분포에서는 표본의 크기라는 개념이 존재하지 않기 때문에 확률변수의 최대값 또한 개념상으로는 제한이 없다.  
예를 들어 오후 1시에서 오후 2시 사이에 은행을 방문하는 고색의 수는 0이상의 모든 정수가 될 수 있다.  
그러나 셀 수 없을 정도로 큰 수를 갖는 확률변수는 포아송분포한다고 보지 않는 것이 일반적이다.  
이러한 포아송분포의 기본적인 가정은 다음과 같다.

1. 일정한 단위시간이나 단위길이 혹은 단위 면적 들에서 발생하는 사건들은 셀 수 있을 정도의 수이며, 서로 독립적이다.  
2. 극히 작은 단위시간과 단위면적 등에서는 한 번에 둘 이상의 사건이 동시에 발생할 확률은 매우 작기 때문에, 이러한 사건이 발생할 확률은 0으로 간주한다.  
3. 일정한 단위시간이나 단위 면적에서 발생하는 사건의 수는 단위시간이나 단위면적의 크기에 비례한다.  

### 포아송분포의 확률 질량 함수

일정한 단위시간이나 단위길이 혹은 단위면적에서 발생하는 사건의 횟수를 표시하는 확률변수(X)값이 x일 확률,  
관측하려는 사건이 x번 발생할 확률을 나타내는 포아송분포의 확률질량함수는 아래에 보이는 식과 같다.  
그리고 각각의 변수의 뜻은 다음과 같다.  

1. 람다값은 일정한 측정단위당 평균적으로 발생하는 사건의 횟수, 혹은 그 기대값을 말한다.  
2. x는 정해진 단위시간이나 단위면적에서 발생하는 사건의 수, 즉 확률변수값을 나타낸다.  
3. 또한 e는 exponential의 약자로서 자연로스의 밑이 되는 지수를 의미하여 그 값은 2.71828이 된다.  

시간을 무한히 작은 미소단위로 나누었을 때,  
이항분포로부터 유도되는 식을 통해서 확률밀도함수, 분산, 평균등을 구한다. 

### 이항분포와 포아송분포와의 관계

여러 개의 베르누이 확률변수 값의 합으로 인식되는 이항확률변수의 분포인 이항분포와  
일정한 단위 내에 발생하는 사건의 수를 나타내는 포아송확률변수의 분포인 포아송분포는 서로 무관하지 않다.  


### 각 분포의 확률함수들과 평균, 분산, 표준편차

* 이항분포
	* 확률함수: ![binom](http://bit.ly/2uY0FGW)
	* 평균: 
	* 분산
	* 표준편차

* 초기하분포
	* 확률함수: ![hyper\-geomeric](http://bit.ly/2uXPpKC)
	* 평균
	* 분산
	* 표준편차

* 포아송분포
	* 확률함수: [poisson](http://bit.ly/2uXRN40)
	* 평균
	* 분산
	* 표준편차

## 8. 연속확률분포

확률분포는 일반적으로 확률변수가 가질 수 있는 값들을 셀 수 있는가의 여부에 따라  
이산확률분포와 연속확률분포로 나누어진다. 제7장에서는 이산확률분포에 대해서 설명하였고,  
본 장에서는 연속확률분포에 대해서 알아보도록 한다. 대표적인 연속확률분포에는 정규분포와 t분포,  
그리고 카이제곱(X^2)분포와 F분포가 있으며, 또한 이산확률분포의 하나인 포아송분포와 밀접한 관련이 있는 지수분포가 있다.  


### 정규분포

정규분포(normal distribution)는 연속확률분포 중에서 가장 대표적인 분포로서  
통계학과 조사방법론에서 가장 많이 사용되는 확률분포이다. 사람들의 몸무게와 키, 그리고 지능지수(IQ)와 같은 대부분의 변수들은  
정규분포를 한다고 할 수 있으며, 특히 이들을 모집단으로 하여 추출한 표본의 평균(표본평균)은 관측치의 수가 많아질수록  
정규분포에 더욱 가까워진다. 이러한 정규분포의 가장 큰 특징은 좌우대칭인 종 모양을 이루고 있다는 것이다.  


정규분포의 확률밀도함수는 ...(중략)... 이며, 정규분포의 모양을 결정짓는 모수(parameter)로는 위치모수(location parameter)인 평균과  
척도 모수(scale parameter)인 분산이 있다. 또한 식에서 PI는 원주율을 나타내는 무리수이며 e는 자연로그의 밑수로 쓰이는 무리수다.  
이제 정규분포의 특징을 살펴보자.  

1. 평균을 중심으로 좌우대칭인 종모양을 하고 있다.
2. 둘째, 정규분포는 평균을 중심으로 좌우 1개의 표준편차 안에 측정된 관측치, 즉 확률변수값들의 68.26%가 포함되어 있어야 한다.  
	* 좌우 2개의 표준편차 안에는 95.44%의 확률변수값들이 있어야 하며,  
	* 좌우 3개의 쵸준편차 안에는 99.74%에 이르는 대부분의 값들이 있다.  
3. 정규분포의 위치와 모양을 결정하는 모수는 평균과 분산이다. 
	* 따라서 정규분포의 모양은 평균과 분산에 따라서 달라진다.  
4. 일반적으로 평균이 u이고 분산이 sigma^2인 정규분포는 N(u, sigma^2)으로 표기한다.  
	* 따라서 X ~ N(u, sigma^2)이라는 표기는 변수 X가 평균이 u이고 분산 sigam^2인 정규분포를 한다는 의미이다.  
	* 예를 들면, X ~ N(5, 16)이라는 표기는 확률변수 X는 평균이 5이고 분산이 16인 정규분포를 한다는 의미이다.  



### 표준정규분포

정규분포는 평균과 분산의 크기에 따라 여러가지 형태를 갖는다. 따라서 서로 다른 두 개의 분포를 비교하거나  
확률분포상 면적의 크기를 계산하여 확률을 알아내는 것은 쉽지 않다.  


표준편차의를 변수값의 단위로 하여 만들어진 정규분포를 표준정규분포(standard normal distribution)라고 한다.  
이러한 표준정규분포(N(0, 1))는 평균이 0이고 분산이 1인 정규분포로서 표준편차를 변수값의 단위로 사용하기 때문에  
모든 정규분포는 표준정규분포로의 전환이 가능하다.  


표준정규분포는 평균이 0이고, 분산이 1이기 때문에 표준정규분포의 확률밀도 함수식에는 평균과 분산이 별도로 표시되지 않는다.  
즉, 표준정규분포는 일반정규분포와는 달리 평균과 분산에 대하여 **독립적**이다.  
이러한 표준정규분포는 확률변수를 Z로 표시하기 때문에 Z라고도한다.  

* 그렇다면 표준화는 구체적으로 어떤 과정을 통해서 할까?
> 표준화(X를 Z로 치환한다. Z = (X - u)/sigma  
	
### t분포

정규분포와 같이 좌우대칭이라는 점은 정규분포와 같으나 정규분포와는 달리  
평평하고 두터운 꼬리모양을 가진 구릉모양의 분포를 **t분포**라고 한다.  


일반적으로 자유도가 n-1인 확률변수(t(n-1))는 표준정규분포하는 확률변수 Z를 분자로 하고,  
자루도가 n-1인 카이제곱 확률변수(X^2(n-1))를 n-1로 나눈 평균 카이제곱 확률변수값의 제곱근을 분모로하는 확률변수로 정의된다.  

#### t분포의 특징

1. 표준정규분포와 같이 평균이 0을 중심으로 좌우대칭인 낮은 구릉이나 종모양을 하고 있다.  

2. 자유도(n-1), 즉, 표본평균을 구하는데에 사용된 관측치의 수(n)에 따라 모양이 변한다.  
	* 일반적으로 t분포의 모양은 자유도(n-1)가 적을수록 표준정규분포보다 더 평평하고 두터운 꼬리모양을 가진다.
	* 그러나 자유도가(n-1)가 증가함에 따라 분산은 1에 접근하며, 
	* 표본의 크기(n)가 30개 이상이면 t분포는 표준정규분포와 거의 동일한 모양의 분포를 한다.

3. 또한 표본의 크기(n)가 30개 이상일 경우 확률변수 t의 분포는 표준정규분포와 거의 동일하기 때문에 t분포 대신에 Z분포를 사용하여 값을 구할수도 있다.  
	* 그러나 역으로 표본의 수가 30개 미만이라면 Z분포를 사용하여 통계분석을 할 수 없다.  

4. 이처럼 t분포의 특수한 형태가 Z분포이므로, t분포가 Z분포를 포함한다고 볼 수 있다.  
	* 이러한 이유로 통계분석에서 Z분포보다는 t분포가 주로 사용된다.
	* 따라서 앞으로 설명할 추정 및 가설검정과 같은 대부분의 통계분석에서는 표본의 크기(n)가 큰 경우는 물론
	* 표본의 크기(n)가 작을 경우에도 적용할 수 있는 t분포가 사용된다.  

### 카이제곱 분포

카이제곱분포는 1900년경 칼 피어슨 (Karl Pearson)에 의해 개발되어   
모집단 분산에 대한 가설검정이나 교차분석에서 유용하게 사용되는 분포이다.   

#### 카이제곱 분포의 특징

1. 연속확률분포로서 확률변수는 항상 양의 값만을 갖는다.  
2. 오른쪽 꼬리를 가진 비대칭 분포이다.
3. 카이제곱분포는 t분포와 마찬가지로 자유도에 의해서 모양이 결정된다.  
4. 카이제곱분포도 t분포처럼 자유도가 커짐에 따라 좌우대칭인 정규분포에 접근하게 된다.  

#### 카이제곱 분포의 정의

서로 독립적인 표준확률변수를 Z1, Z2, Z3, Z4, ... Zn을 제곱하여 더한 값을 변수값으로 하는 확률변수  

> X^2(n) = Z1^2 + Z2^2 + Z3^2 + Z4^2 + ... + Zn^2

는 자유도가 n인 카이제곱(X^2)분포를 한다.  

1. 평균이 u이고 분산이 sigma^2인 정규분포(N(u, sigma^2))에서 서로 독립적인 x1, x2, x3을 표본으로 추출였을 경우 이들은 정규분포하는 확률변수값들이 된다.  

2. 정규분포하는 확률변수 x(i)를 표준화한 확률변수 Z(i) = (x(i) = u)/sigma는 표준정규분포하는 확률변수가 된다.  

3. 확률변수 x(i)(i = 1, 2, 3, ..., n)가 독립적으로 이를 표준화한 확률변수 Z(i)(Z(i) = (x(i) - u)/sigma)도 서로 독립적이다.  

4. n개의 표준확률변수 Z(i)를 제곱하여 더한 값을 변수값으로 하는 확률변수(X^2)는 자유도가 n인 카이제곱(X^2)분포를 한다.  


#### 표본의 분산과 모집단 분산의 비로 표시되는 카이제곱 확률변수의 도출

책181쪽을 참고하라.

### F분포

카이제곱분포와 유사한 모양의 분포를 갖는 비대칭 연속확률분포 중에는 F분포(Fisher distridution)가 있다.  

### 지수분포

일정한 단위 시간이나 단위거리 또는 담위 면적에서 발생하는 사건의 횟수를 확률변수로 하는 분포를 포아송분포라고 한다면,  
이렇게 발생하는 사건과 사건 사이의 시간, 즉 한 사건이 일어난 후에 다음 사건이 일어날 때까지 걸린 시간을  
변수값으로 하는 확률 변수는 연속확률 변수가 되며, 이 때의 확률변수는 지수분포(exponential distribution)를 한다.  
이러한 포아송분포와 지수분포를 구별해보자.


포아송분포는 일정한 시간이나 구간에서 어떠한 사건이 일어날 성공횟수를 확률변수값으로 하는 반면에,  
지수분포는 한 사건이 발생한 후에 다음 사건이 발생할 때까지의 시간을 확률변수값으로 하는 분포를 말한다.  
예를 들어, 새로 구입한 자동차에서 발견되는 흠집 수, 하루에 고장나는 기계 대수, 1달 동안 아파트 엘리베이터가 고장난 건수  
등등 이런 종류의 확률젼수는 포아송분포를 한다고 앞서 설명했다.  


반면에 새로 구입한 자동차에서 1개의 흠집이 발겨된 후에 또 다른 기계 1대가 고장날 때까지 걸리는 시간,  
또한 112, 114, 119 전화교환대에 전화가 걸려온 후에 또 다른 전화가 걸려올 때까지 걸리는 시간등을 변수값으로 하는 확률변수는 지수 분포를 한다.  


지수분포를 하는 확률변수의 확률밀도함수는 다음과 같이 정의된다.

* 확률밀도함수: ![exponentiation](http://bit.ly/2t9N5Ty)
* 평균: ![exponentiation-mean](http://bit.ly/2uYFNz9)
* 분산: ![exponentiation-var](http://bit.ly/2uYTvCb)
* 표준편차: ![exponentiation-dev](http://bit.ly/2uYxyDc)

#### 지수분포의 특징

1. 확률변수 X의 값이 증가함에 따라 오른쪽꼬리 부분이 감소하는, 즉 오른쪽으로 경사진 모양의 분포를 한다.
	* 여기에 더해, 지수분포는 **_종모양이 아니다._**
2. 분포 모양은 일정한 단위시간이나 단위면적 등에서 발생하는 사건의 평균발생횟수를 나타내는 람다값에 따라 달라진다.
3. 람다값이 크면 클수록 수직축의 절편값이 커진다.  
4. 지수분포를 하는 확률변수의 평균과 표준편차는 같다.  

## 모집단의 평균에 대한 가설검정
일반적으로 가설검정은 연구가설이 객관적인 검정을 통하여 옳다는 것이 밝혀지기 전까지는  
아직 귀무가설이 옳다는 전제하에서 검정이 진행된다.  
가설검정을 크게 나누면 모집단의 평균이나 비율에 대한 가설검정과 분산에 대한 가설검정으로 구분할 수 있다.  

### 모집단의 평균에 대한 가설검정

모집단이 1개인 단일 모집단 평균에 대한 가설검정은 모집단의 평균이 어떠하다는 **가설이 맞는지 검정하는 것**이다.  
2개의 모집단평균에 대한 가설검정은 **2개 모집단의 평균이 서로 다른지 혹은 어느 것이 더 큰지에 대하여 가설을 검정**하는 것이다.
이 또한 2개의 모집단에서 각각 뽑은 표본의 평균값들을 서로 비교하여 가설을 검정한다.  
더 나아가 모집단이 3개 이상인 경우에는 **이들 모두의 평균이 같은지 아니면 서로 다른 것이 있는지를 분산분석을 통하여 검정**한다.  


또한 단일 모집단에 대한 가설검정은 **일반적인 단일 모집단 평균에 대한 가설검정과 쌍체비교로 나누어진다.**  
쌍체비교는 동일한 표본을 대상으로 실험을 실시하기 전에 측정한 값과 실험 후에 측정한 값과의 차이가 어떠한가를 분석하여 검정하는 것이다.  
(즉, 쌍체비교에는 실험과정이 들어가기 떄문에 더 많은 수고가 들어간다.)

### 단일 모집단 평균에 대한 가설검정

단일 모집단 평균에 대한 가설검정을 세부적으로 구분하면 일반적인 단일 모집단평균에 대한 가설검정과 쌍체비교로 나누어 볼 수 있다.  
또한 검정의 종류도 설정된 가설에 따라 양측검정, 왼쪽꼬리검정, 그리고 오른쪽꼬리검정의 3가지로 나누어진다.  


#### 가설과 검정의 종류

단일 모집단평균에 대한 가설검정은 모집단의 평균(mu)에 대하여 지금까지 알려진 일반적인 이론이나 사실,  
즉 모집단의 평균은 어느 특정한 값(a)이라는 믿음에 대해 연구자가 이의를 제기함으로써 시작된다.  
그리고 연구가설이 어떨게 설정되는가에 따라서 검정종류도 양측검정, 왼쪽꼬리검정, 그리고 오른쪽꼬리검정으로 나누어진다.  

#### 유의수준

일반적으로 가설이 설정되고 설정된 가설에 따라 검정의 종류가 결정되면,  
다음으로 가설검정의 통계적 유의수준(alpha), 즉 귀무가설을 기각하고 연구가설을 채택할 확률을 정한다.  


유의수준이 결정되면 다음으로 검정의 종류(양측, 왼쪽꼬리, 오른쪽꼬리)에 따른 임계치를 산출하고,  
이를 기준으로 표본조사를 통해 얻은 통계량 값이 어디에 위치하는가에 따라 가설의 채택 여부를 판단하여 검정한다.  
일반적으로 유의수준이 작을구록 우측으로는 더욱 큰 값, 좌측으로는 더욱 작은 임계치가 설정됨으로써  
표본으로부터 구한 검정통계량도 이들보다 더 크거나 작어야 귀무가설을 기각할 수 있기 때문에 연구가설이 채택될 확률은 낮아진다.  
따라서 작은 유의수준(alpha)의 검정에서 채택된 연구가설일수록 그 결과를 더욱 신뢰할 수 있다.  

#### 검정기준에 따른 검정방법

평균에 대한 가설검정은 무엇을 기준으로 검정하느냐에 따라 다음 3가지 방법이 있을 수 있다.  

1. 일반적으로 모집단을 구성하고 있는 변수의 단위, 즉 표본으로부터 얻은 통계량을 그대로 검정통계량(t)으로 사용하여 검정하는 방법이다.  
2. 중심극한정리에 의하여 표본평균(x-bar)이 t(Z)로 분포한다는 가정하에 통계량 값을 표준화하여,  
	* t(Z)값으로 치환한 값을 검정통계량으로 하여 검정하는 방법이다.  
3. 표본통계량값에 상응하는 p값(p-value)을 구하여, p값이 유의수준보다 작을 경우에는 연구가설을 채택하고, 반대로 크면 연구가서을 기각하는 식으로 검정하는 방법이 있다.  
	* 그러나 p값을 이용한 검정의 경우도 통계량의 p값을 구하기 위해서는 일반적으로 통계량 t값을 먼저 산출해야 하기 때문에  
	* 사실상 두 번째 방법과 유사한 방법이라 볼 수 있다.  

#### 가설검정

1. 표본평균을 검정통계량으로 사용하는 검정(예시: 양측검정)
	* 유의수준을 이용하여 표본평균과 같은 단위의 값으로 표현되는 임계치를 구한다.  
	* 이 경우 분포의 평균은 귀무가설에서 주장하는 대로 a로 가정하고 이를 중심으로 좌우 임계치를 계산한다.  
	* 임계치는 11장에서 설명한 바와 같이 유의수준과 표본평균의 표준편차인 표준오차에 의해서 결정이 된다.  
	* 이렇게 좌우 임계치가 결정된 다음, 마지막으로 조사한 표본의 평균이 어디에 위치하느냐에 따라 연구가설의 채택 여부를 결정한다.  
	* 즉, 검정통계량인 표본평균이 좌우 임계치 바깥쪽에 위치하면 연구가설을 채택하고, 안쪽에 위치하면 연구가설을 기각한다.  

2. 표본평균을 표준화한 t값을 검정통계량으로 사용하는 검정
	* 표본의 평균에서 모집단평균을 빼서 얻은 값을 다시 표본평균의 표준편차인 표준오차로 나누면 검정통계량 t값을 구할 수 있다.
	* 가설검정은 귀무가설이 기각되기 전까지는 항상 귀무가설이 옳다는 전제하에 이루어진다. 
	* 따라서 모집단 평균을 나타내는 a를 t값으로 치환하면 분자(a-a)가 0이 되기 때문에 t분포의 중심은 0이 된다.  
	* 또한 좌우측 임계치를 나타내는 c1과 c2도 표준화하여 t분포상의 값으로 치환하면, t분포상의 좌우측 임계치를 나타내는 tc1솨 tc2값들을 구할 수 있다.  
	* 다음으로 통계량인 표본평균을 t값으로 치환하여 얻은 통계량 tx값, 즉 검정통계량이 어디에 위치하느냐에 따라 연구가설의 채택 여부를 결정한다.  
	* 이때 통계량인 표본평균을 표준화한 t값도 일종의 표본통계량임을 유의하여야 한다.  

3. p값을 이용한 가설검정
	* 일반적으로 p값이 유의수준보다 크면 연구가설을 기각하고, 유의수준보다 작으면 연구가설을 채택한다.  
	* 주의: 패키지가 제시하는 p값은 항시 양측검정을 전제로 하여 계산한 p값임을 유의해야 한다. 
	* 따라서 단측검정에 활용하고자 하는 경우에는 p값의 절반만을 실제 p값으로 생각하여 이를 유의수준과 비교해서 검정해야 한다.

#### 단일 모집단 평균에 대한 가설검정 절차

#### 단일 모집단 평균에 대한 가설검정 사례

일단 넘어간다.

### 쌍체비교

일정한 표본을 대상으로 특정한 사건을 전후로 두 번 측정하여 얻은 값들 간에 유의한 차이가 있는지를 검정하는 분석을 쌍체비교라 한다.  
일반적으로 이러한 쌍체비교는 다음에 설명할 독립적인 두 모집단 평균에 대한 검정보다 효율적이다.  


요약하면 쌍체비교는 추가적인 노력으로 보다 정확하고 많은 정보를 가지고 가설을 검정하기 때문에 
서로 독립적인 두 모집단의 평균을 검정하는 방법보다 더 효과적인 검정 방법이다.  
따라서 시간과 비용 그리고 여건등이 허락하면 서로 독립적인 두 모집단의 평균검정보다는 쌍체비교를 이용하는 것이 바람직하다.  
그러나 모든 경우에 쌍체비교를 할 수 있는 것은 아니다. 오히려 쌍체비교를 할 수 있는 경우는 극히 제한되어 있으며 가능하다고 하여도, 많은 노력과 비용을 필요로 한다. 
쌍체비교가 불가능하면 실험 전과 후를 서로 다른 집단으로 인식하여 두 모집단평균에 차이에 대한 검정을 하여야 한다.  


## 두 모집단 평균에 대한 가설검정

두 모집단평균에 대한 가설검정은 쌍체비교에서처럼 차이를 비교를 하는 것이지만, 모집단이 하나가 아니고 두 개이며,  
이들 모집단들은 서로 연계된 정보가 없어 쌍체비교가 불가능한 경우 실행하는 검정을 말한다.  

### 두 모집단평균에 대한 가설검정 절차



### 두 모집단평균에 대한 가설검정 사례



## 모집단의 비율에 대한 가설검정

모집단비율에 대한 가설검정을 설명하기에 앞서서, 평균에 대한 가설검정의 경우와 비교하여 비율에서 사용되는 기호와 값들에 대하여 명확하게 이해할 필요가 있다.  
비율에 대한 검정에서는 모집단의 평균에 해당하는 모집단의 비율은 PI로 표시하며,  
모집단의 분산에 해당하는 모집단 비율의 분산은 PI\*(1 -PI)가 된다. 그리고 표본의 평균에 해당하는 표본의 비율은 p로 표시하고,  
표본평균의 표준편차, 즉 표준오차는 모집단비율의 분산(PI\*(1 - PI))을 표본의 크기로 나누어서 루트를 씌운 값  
(sqrt(PI\*(1 - PI)/n))으로 표현할 수 있다.  


일반적으로 비율이 아닌 평균의 가설검정에서 표준오차를 구하는 경우에는 모집단의 분산을 모르기 때문에 표본의 분산을 대신해서 사용한다.  
즉, 모집단의 분산을 알 수 없기 떄문에 모집단 분산의 불편추정량인 표본의 분산을 이용하여 표준오차를 계산한다.  
그러나 표본비율의 표준오차를 산출하는 경우에는 표본의 분산 표본의 분산에 해당하는 표본비율의 분산인 p(1 - p)를 사용하지 않고,  
귀무가설에서 주장하는 모집단 비율(PI)을 이용한 모집단비율의 분산, 즉 PI(1 - PI)를 구한다음 이를 이용하여 표준오차를 구한다.  


그러나 두 모집단 비율에 대한 가설검정에서는 귀무가설에서 구체적인 모집단비율값을 제시하지 않고  
두 모집단비율의 크기를 비교하는 내용만 있기 때문에 이러한 정보만으로는 두 모집단비율 차이의 분산을 구할 수 없다.  
따라서 두 모집단 비율 검정에서는 두 집단의 표본비율(p1, p2)을 이용하여 두 모집단 비율 차이의 분산과 표준오차를 구해서   
가설검정해야 한다. 

### 단일 모집단의 비율에 대한 가설검정 절차

단일 모집단 비율에 대한 가설검정은 하나의 모집단비율에 대한 연구가설을 세우고,  
모집단으로부터 추출한 표본의 비율(p)로 연구가설에서 주장하는 모집단의 비율이 합당한지를 검정하는 것이다.  
주의점은 표본비율의 표준오차를 구할 때 표본비율의 분산을 사용하지 않고 모집단비율의 분산을 사용한다.  


### 단일 모집단의 비율에 대한 가설검정 사례

#### 양측검정
#### 오른쪽꼬리검정

### 두 모집단비율에 대한 가설검정 절차

귀무가설에서 두 모집단 비율의 구체적인 값들이 제시되지 않기 때문에 모집단 비율값으로 검정과정에서 필요로 하는  
표준오차를 구할 수 없다. 따라서 두 모집단의 비율 검정에서는 모집단 비율 대신에 표본의 비율값들(p(a), p(b))을 이용하여 표준오차를 구한다.  

### 두 모집단비율에 대한 가설검정 사례

#### 양측검정
#### 오른쪽꼬리검정
#### 왼쪽꼬리검정


## 모집단의 분산에 대한 가설검정

어느 사람이나 사물을 다른 사람이나 사물들과 구분지을 수 있는 특징을 나타내는 값은 매우 많으며 다양하다.  
우기가 관심을 가지고 분석하는 모집단의 경우에도, 모집단의 특성을 나타내는 값인 모수는 매우 많다.  
일반적인 경우 한 사람을 다른 사람들과 구분하는 가장 대표적인 값은 성과 이름이라고 할 수 있다.  
같은 맥락에서 모집단을 다른 모집단과 구분하는 가장 중요한 값들, 즉 사람의 성과 이름에 해당하는 값들이 바로 평균(mu)과 분산(sigma^2)이다.  


모집단을 구성하는 값들이 평균으로부터 퍼져 있는 정도를 나타내는 분산에 관심을 가지고 이에 대해 가설을 세우고 이를 검정하는 것이 바로 모집단분산에 대한 가설검정이다.  


단일 모집단에 분산에 대한 검정은 카이제곱분포를 이용한 카이제곱검정이 되고,  
두 모집단의 분산에 대한 검정은 F분포를 이용한 F검정이 된다.  


참고로 평균이나 분산은 이렇게 모집단의 갯수에 따라서 적합한 검정을 사용한다.  
하지만 모집단의 비율은 딱히 그런 경향을 보이지 않는다.  
또한 평균이나 비율의 경우 분포의 모양이 평균을 중심으로 하여 대칭인 경향을 보이지만,  
분산은 한쪽으로 치우친 모양(비대칭)을 하고 있다.  


### 단일 모집단분산에 대한 가설검정

#### 단일 모집단분산에 대한 가설검정 절차

단일 모집단분산에 대한 가설검정은 단일 모집단평균에 대한 가설검정과 유사하다.  
즉, 평균에 대한 가설검정에서 평균 대신에 분산이 사용된다는 점만 다르다.  


단일 모집단 분산에 대한 가설검정세는 카이제곱분포가 사용된다. 카이제곱분포는 t분포처럼 자유도(df)에 따라 그 모양이 달라지나 일반적으로 오른쪽 꼬리모양의 비대칭분포이다.  
따라서 카이제곱분포상의 임계치는 유의수준과 자유도(df = n - 1), 그리고 검정의 종류(양측검정, 왼쪽꼬리검정, 오른쪽꼬리검정)에 의하여 결정이 된다.  


일반적으로 카이제곱분포표에 있는 확률값은 특정한 X^2값으로부터 무한대 까지의 면적을 나타낸다.  
따라서 임계치를 구하는 경우에는 임계치로부터 오른쪽 무한대까지의 면적을 나타내는 확률값을 고려해서 구해야 한다.  
이와 같이 카이제곱분포상의 양측 임계치가 대칭이 아닌 형태로 표시되는 이유는 카이제곱분포가 대칭이 아니기 때문이다.  


임계치가 구해지면, 다음으로 표본의 분산과 모집단의 분산, 그리고 자유도(df = n - 1)를 이용하여  
검정에 사용되는 검정통계량인 X^2값을 적절한 공식을 사용해서 구한다.  



#### 단일 모집단분산에 대한 가설검정 사례

#### 양측검정
#### 오른쪽꼬리검정

### 두 모집단분산에 대한 가설검정

두 모집단분산에 대한 가설검정은 두 모집단의 평균에 대한 검정과 마찬가지로, 두 모집단의 분산이 같은지  
아니면 어느 쪽의 분산이 더 큰지를 검정하는 것이다.  
두 모집단으로부터 추출된 표본분산의 비를 변수값으로 하는 확률변수를 확률변수 F로 나타내며 이 확률변수 F는 F분포한다.  
따라서 두 모집단분산에 대한 가설검정은 F분포를 이용하게 된다.  

### 비대칭 F분포의 특성

F분포는 모집단으로부터 추출한 표본이 2개이기 때문에 2개 표본의 자유도에 따라 분포의 모양이 변하는 좌우 비대칭 모양의 분포이다.  
즉, 두 표본의 분산비로 표시되는 확률변수 F의 분포는 분자와 분모에 해당하는 이들 2개 표본분산의 자유도 값에 의하여 분포의 모양이 확정된다.  
어느 표본의 분산이 분자나 분모가 되는가에 따라 통계량 F값이 달라지며 이에 따른 F분포의 모양도 다르게 나타난다.  
따라서 이들 분자와 분모에 따라 결정되는 자유도의 순서는 F분포의 모양을 결정짓는 매우 중요한 요인이 된다.  
F분포는 카이제곱분포와 비슷한 모양을 띄고 있으며, F분포표는 X^2분포표와 마찬가지로, 특정한 F값으로부터 무한대에 이르는 면적으로 표시되는 확률값들을 제시하고 있다.  


일반적으로 임계치는 두 표본분산의 자유도에 의하여 확정된 F분포와 유의수준,  
그리고 검정의 종류(양측 혹은 단측)에 따라 결정된다.  

### 두 모집단분산에 대한 가설검정 절차

두 모집단분산에 대한 가설검정에서는 카이제곱(X^2)분포를 사용하는 단일 모집단분산에 대한 가설검정과는 달리 F분포가 사용된다.  
F분포는 모집단이 2개이고, 이에 따라 표본도 2개이기 때문에, 2개 표본의 자유도(n(a)-1, n(b)-1)에 따라 그 모양이 달라지지만, 일반적으로 오른쪽꼬리가 긴 비대칭분포 모양을 갖는다.  
F분포상의 임계치는 유의수준과 2개의 자유도, 그리고 검정의 종류에 의하여 결정이 된다.  


대부분의 F값은 t값이나 X^2값처럼 통계학이나 조사방법론 책 뒤에 부록으로 제시된 표를 이용하면 쉽게 찾을 수 있다.  
그러나 항상 양의 값을 갖는 F분포는 t분포와는 달리 좌우대칭이 아니라 X^2분포와 같이 오른쪽꼬리 모양의 비대칭 분포라는 점에 유의하여야 한다.  


일반적으로 F분포표에 있는 확률값은 특정한 F값으로부터 무한대까지의 면적을 나타낸다.  
따라서 임계치를 구할 경우에는 그 값부터 오른쪽 무한대까지의 면적을 나타내는 확률을 고려해서 구해야 한다.  


### 두 모집단분산에 대한 가설검정 사례

#### 양측검정
#### 오른쪽꼬리검정

## 분산분석

**분산분석은 집단간 평균의 차이를 검정하는 분석방법이다.**
일반적으로 집단이 2개인 경우에는 t검정으로 집단간 평균차이를 검정할 수 있다.  
그러나 집단이 3개 이상인 경우 t검정으로 집단간 평균 차이를 한번에 분석하기는 어렵다.  
이처럼 집단이 3개 이상인 경우에 집단간 평균차이를 동시에 비교 검정할 수 있는 방법이 바로 분산분석이다.  
즉, 3개 이상의 집단간 평균이 서로 차이가 있는지를 검정하는 분석방법이다.  


또 다른 각도로 분산분석을 설명하면, *분산분석은 제 17장에서 설명하는 회귀분석과 같이  
독립변수가 종속변수에 미치는 영향을 분석하는 방법 중의 하나이다.*  

## 연관성분석

## 회귀분석

## 비모수 통계분석

## 참고문헌

* 이훈영 교수의 통계학 - 이훈영 - 도서출판 청람

1. 모집단의 평균에 대한 가설검정
	* 모집단의 갯수에 따라 방법과 목적이 달라진다.
		* 모집단이 1개면 연구가설이 맞는지 귀무가설이 맞는지 알아보기 위해서 가설검정을 실시한다.
		* 또한 모집단이 1개에 몇가지 조건이 충족되면 쌍체비교를 실시할 수 있는데, 이는 더 많은 공을 들여서 보다 정확한 가설검정을 하는 방법이다.
		* 모집단이 2개면 둘중에 어떤 모집단의 평균이 더 큰지, 작은지 알아보고자하는 목적으로 가설검정을 실시한다.
		* 모집단이 3개면 셋중에 어떤 모집단이 다른 모집단과 다른지 알아보고자하는 목적으로 가설검정을 실시한다.
	* 평균에 대한 가설검정 방법은 크게 3가지로 나눌 수 있다.  
		* 표본에서 얻은 표본통계량을 그대로 검정통계량t로 사용하는 방법이 있다.  
		* 중심극한정리를 활용하여 표본평균이 t(Z)를 따른다는 가정을 통해서 치환한 다음 t가 임계치를 넘어가는지 아닌지 알아보면 된다.
		* t를 사용하는 방법이 가장 보편적이다.  
		* 그리고 p값(p-value)를 사용하는 방법이 있다. p값이 유의수준 보다 작으면 연구가설을 기각한다.
		* p값이 유의수준보다 크면 연구가설을 채택한다.
		* p값은 유의수준과 같은 단위(확률값)을 사용하기 때문에 비교가 용이하다.
		* 주의점: 패키지를 사용하는 경우 p값은 양측검정을 기준으로 하기 때문에, 단측검정에 활용하려면 그 p값은 절반으로 나누어서 사용하라.

2. 모집단의 비율에 대한 가설검정

* 용어정리
	* 모집단의 비율: PI
	* 모집단비율의 분산: PI(1 - PI)
	* 모집단비율의 표준오차 : (sqrt(PI(1-PI)/n))
	* 표본의 비율: p
	* 표본비율의 분산: p(1 - p)
	* 표본비율의 표준오차: (sqrt(p(1-p)/n))
* 주의점
	* 표본비율의 표준오차를 산출하는 경우에는 표본비율의 분산을 사용하지 않고, 모집단 비율의 분산을 사용해서 구한다.  
	* 그러나 두 모집단비율 검정에서는 구체적인 모집단비율값을 알려주지 않는다.  
	* 따라서 두 모집단비율 검정에서는 두 집단의 표본비율을 이용하여 두 모집단비율 차이와 분산과 표준오차를 구해서 가설검정해야 한다.  


3. 모집단의 분산에 대한 가설검정


4. 분산분석?
	* 3개 이상의 모집단들의 평균차이를 동시에 비교 검정하는데 유용한 방법
	* 다른 관점에서 보면 회귀분석과 마찬가지로 독립변수가 종속변수에 미치는 영향을 분석하는 방법 중의 하나이다.


